{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "e680f26c",
      "metadata": {
        "id": "e680f26c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/akshay5305/CNN-vs-VIT-for-Medical-Imaging.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-lViWs2lBC_",
        "outputId": "bdde49f8-22a5-4110-ef04-4d74116a02f3"
      },
      "id": "Y-lViWs2lBC_",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CNN-vs-VIT-for-Medical-Imaging'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 20 (delta 2), reused 9 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 6.74 KiB | 6.74 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CNN-vs-VIT-for-Medical-Imaging\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EtbVTFTlBZC",
        "outputId": "0c5e67fa-f7b6-42bd-afd0-706482fe32b0"
      },
      "id": "1EtbVTFTlBZC",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CNN-vs-VIT-for-Medical-Imaging/CNN-vs-VIT-for-Medical-Imaging/CNN-vs-VIT-for-Medical-Imaging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"vuppalaadithyasairam/bone-fracture-detection-using-xrays\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "vYVesgrOlU6U",
        "outputId": "52ff4608-0a88-412a-8435-aa67d56c015d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vYVesgrOlU6U",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/vuppalaadithyasairam/bone-fracture-detection-using-xrays/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "BASE_PATH = \"/kaggle/input/bone-fracture-detection-using-xrays/archive (6)/val\"\n",
        "\n",
        "for root, dirs, files in os.walk(BASE_PATH):\n",
        "    print(root, \"->\", dirs)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "LAS09zPPuEZA",
        "outputId": "aec85481-3ee5-4613-f6f3-075bbcb7779e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LAS09zPPuEZA",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/bone-fracture-detection-using-xrays/archive (6)/val -> ['not fractured', 'fractured']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6de5e8f1",
      "metadata": {
        "id": "6de5e8f1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from utils import config as cfg\n",
        "from utils.utils import return_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_ds(input_dir):\n",
        "    train_ds=tf.keras.preprocessing.image_dataset_from_directory(input_dir,\n",
        "    validation_split=0.2,\n",
        "     subset='training',\n",
        "     seed=42,\n",
        "     image_size=(cfg.input_dim,cfg.input_dim),\n",
        "     batch_size=16,\n",
        "     label_mode='categorical',)\n",
        "\n",
        "    val_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        input_dir,\n",
        "        validation_split=0.2,\n",
        "        subset='validation',\n",
        "        seed=42,\n",
        "        image_size=(cfg.input_dim,cfg.input_dim),\n",
        "        batch_size=8,\n",
        "        label_mode='categorical',)\n",
        "\n",
        "    return train_ds, val_ds\n"
      ],
      "metadata": {
        "id": "iROw8t2TlLV7"
      },
      "id": "iROw8t2TlLV7",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_model(input_dim, nb_classes, freeze=False, head=None):\n",
        "    if head=='xception' or head=='Xception':\n",
        "        base_model=Xception(include_top=False,weights='imagenet',input_shape=(input_dim,input_dim,3))\n",
        "\n",
        "    if head=='vg16' or head=='VGG16':\n",
        "        base_model=VGG16(include_top=False, weights='imagenet',input_shape=(input_dim,input_dim,3))\n",
        "\n",
        "    if head=='inceptionv3' or 'Inceptionv3' or 'InceptionV3':\n",
        "        base_model=InceptionV3(include_top=False, weights='imagenet',input_shape=(input_dim,input_dim,3))\n",
        "\n",
        "    if head=='densenet121':\n",
        "        base_model=DenseNet121(include_top=False, weights='imagenet',input_shape=(input_dim,input_dim,3))\n",
        "\n",
        "    if not head:\n",
        "        print('Please choose pre trained model')\n",
        "\n",
        "    print('Choose smodel is ', head)\n",
        "\n",
        "    if freeze:\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable=False\n",
        "\n",
        "    x=base_model.output\n",
        "    x=GlobalAveragePooling2D()(x)\n",
        "\n",
        "    predictions=Dense(nb_classes,activation='softmax')(x)\n",
        "    model=Model(inputs=base_model.inputs, outputs=predictions)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "A4Em49LSlM2D"
      },
      "id": "A4Em49LSlM2D",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__=='__main__':\n",
        "    classes=return_classes('utils/annotation.txt')\n",
        "    train_ds,val_ds=return_ds('/kaggle/input/bone-fracture-detection-using-xrays/archive (6)')\n",
        "    model=return_model(cfg.input_dim,len(classes),head=cfg.head,freeze=True)\n",
        "\n",
        "\n",
        "    model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=SGD(learning_rate=cfg.lr),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    save_weights = ModelCheckpoint(filepath='models/xception_freeze_model_40_epoch.h5', monitor='val_accuracy',\n",
        "                                    verbose=1, save_best_only=True, save_weights_only=False, mode='max')\n",
        "\n",
        "    model.fit(train_ds, epochs=cfg.epochs, validation_data=val_ds, callbacks=[save_weights])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyA7yzsKlOM6",
        "outputId": "5240e964-63e2-4c4f-ca18-a1b7d7bb8523"
      },
      "id": "FyA7yzsKlOM6",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9463 files belonging to 2 classes.\n",
            "Using 7571 files for training.\n",
            "Found 9463 files belonging to 2 classes.\n",
            "Using 1892 files for validation.\n",
            "Choose smodel is  xception\n",
            "Epoch 1/40\n",
            "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8862 - loss: 166.3863\n",
            "Epoch 1: val_accuracy improved from -inf to 0.06395, saving model to models/xception_freeze_model_40_epoch.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 122ms/step - accuracy: 0.8862 - loss: 166.3060 - val_accuracy: 0.0640 - val_loss: 1939.0114\n",
            "Epoch 2/40\n",
            "\u001b[1m473/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9021 - loss: 117.5718\n",
            "Epoch 2: val_accuracy improved from 0.06395 to 0.93605, saving model to models/xception_freeze_model_40_epoch.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 80ms/step - accuracy: 0.9021 - loss: 117.4190 - val_accuracy: 0.9360 - val_loss: 148.0674\n",
            "Epoch 3/40\n",
            "\u001b[1m473/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9196 - loss: 59.6745\n",
            "Epoch 3: val_accuracy improved from 0.93605 to 0.94027, saving model to models/xception_freeze_model_40_epoch.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - accuracy: 0.9196 - loss: 59.6431 - val_accuracy: 0.9403 - val_loss: 14.6689\n",
            "Epoch 4/40\n",
            "\u001b[1m473/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9175 - loss: 58.5641\n",
            "Epoch 4: val_accuracy did not improve from 0.94027\n",
            "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 78ms/step - accuracy: 0.9175 - loss: 58.5089 - val_accuracy: 0.9376 - val_loss: 48.7594\n",
            "Epoch 5/40\n",
            "\u001b[1m473/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9305 - loss: 42.3750\n",
            "Epoch 5: val_accuracy did not improve from 0.94027\n",
            "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 78ms/step - accuracy: 0.9305 - loss: 42.3920 - val_accuracy: 0.9207 - val_loss: 19.1556\n",
            "Epoch 6/40\n",
            "\u001b[1m372/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.9267 - loss: 53.1116"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkJ7ClS7mEMA"
      },
      "id": "UkJ7ClS7mEMA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85ae1d4NlY37"
      },
      "id": "85ae1d4NlY37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EoaXFkUXmiJQ"
      },
      "id": "EoaXFkUXmiJQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}